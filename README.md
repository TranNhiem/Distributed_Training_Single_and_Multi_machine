# Distributed_Training_Single_and_Multi_machine

## Distributed Training on **Single Machine** 


### Tensorflow 

1. Configureation and Consideration 

2. Preparing Dataset for Training 

3. Training Aggregate update Gradient

4. Training Loss update

5. Example the Training Loop for Single Machine

### Pytorch 
+ Update SOON

## Distributed Training on **Multi-Machines**

### Tensorflow 

1. Configuration and Consideration 

2. Preparing Dataset for Training Across multi-Machine 

3. Training Aggregate Gradient multi-Machine with Synchronize training 

4. Optimization (Communicate + Mixpercision Training)

5. Training loss Update 


